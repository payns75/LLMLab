{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04716e8c",
   "metadata": {},
   "source": [
    "# Input embedding pipeline\n",
    "\n",
    "## Resume\n",
    "\n",
    "- Input Text\n",
    "- Tokenized text\n",
    "- Token IDs\n",
    "- Token embedding\n",
    "- Positional embeddings\n",
    "- Input embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e130e1",
   "metadata": {},
   "source": [
    "## Input text\n",
    "\n",
    "We are going to read a text file than we can use along our exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f932d530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "file_path=\"the-verdict.txt\"\n",
    "\n",
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e59adc",
   "metadata": {},
   "source": [
    "# Tokenized text & Token IDs\n",
    "\n",
    "Tokenizing a text is simply take a text and searching for all words. Putting words into an array and convert it to an IDs that correspond of the index of the word in the text input. We can add special tokens if words are unknow or for exemple to specifiy the end of the text. \n",
    "\n",
    "## Simple code to understand\n",
    "\n",
    "Let's go with a simple code. The 'SimpleTokenizerV2Class.py' class show the code to implement the simple encoder and decoder mechanism.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d5751ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "from SimpleTokenizerV2Class import SimpleTokenizerV2\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text)\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
